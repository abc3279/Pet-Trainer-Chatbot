{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('script.txt', 'r', encoding='utf-8') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "qa = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    if '?' in sentences[i]:\n",
    "        qa.append({'question': sentences[i], 'answer': sentences[i+1]})\n",
    "\n",
    "\n",
    "for item in qa:\n",
    "    print(item['question'], item['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_list = []\n",
    "\n",
    "\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "messages = []\n",
    "\n",
    "messages.append({\"role\": \"system\", \n",
    "                 \"content\": \"당신의 임무는 Question이 질문인지 확인하고, 질문일 경우 Answer가 적절한지 판단하는 것입니다.\"})\n",
    "\n",
    "messages.append({\"role\": \"system\", \n",
    "                 \"content\": \"Question이 질문이 아니라면 'X'를 출력하고, Answer에 대한 판단을 하지 마세요. \\n\"\n",
    "                            \"질문이란 일반적으로 물음표(?)가 포함되거나, 답변을 유도하는 문장이어야 합니다. \\n\"\n",
    "                            \"의문형 표현인 '~인가?'와 같은 문장도 질문으로 간주되며, 문장이 길어지거나 내용이 복잡해지더라도 질문을 정확히 인식할 수 있도록 하세요.\"})\n",
    "\n",
    "messages.append({\"role\": \"system\", \n",
    "                 \"content\": \"Question이 질문이라면, Answer가 적절한지 다음 기준에 따라 판단하세요: \\n\"\n",
    "                            \"1. Answer가 Question과 논리적으로 연관성이 있는가? \\n\"\n",
    "                            \"2. Answer가 Question의 의도를 제대로 반영하는가? \\n\"\n",
    "                            \"3. Answer가 문맥상 자연스러운가?\"})\n",
    "\n",
    "messages.append({\"role\": \"system\", \n",
    "                 \"content\": \"Answer가 적절하면 'O', 적절하지 않으면 'X'를 출력하세요.\"})\n",
    "\n",
    "\n",
    "print(messages)\n",
    "\n",
    "for item in qa:\n",
    "    print(item['question'], item['answer'])\n",
    "\n",
    "    messages.append({\"role\": \"user\", \n",
    "                    \"content\": \n",
    "                    '''\n",
    "                    Question: \n",
    "                    %s\n",
    "                        \n",
    "                    Answer:\n",
    "                    %s\n",
    "                    '''%(item['question'], item['answer'])})\n",
    "\n",
    "    response = openai.chat.completions.create(model = model, messages = messages)\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    if answer in 'O':\n",
    "        qa_list.append({'question': item['question'], 'answer': item['answer']})\n",
    "    \n",
    "    print(answer)\n",
    "\n",
    "    messages.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for item in qa_list:\n",
    "    print(item['question'], item['answer']) # 잘못 판단하는 게 많긴 한데, 원하는 부분은 거의 검출해낸 것 같고, 데이터는 많으니 그냥 다 삭제 진행. 더 성능을 개선하려면 따로 모델을 구성해줘야 할듯.\n",
    "    a.append(item['answer'])\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4346\n"
     ]
    }
   ],
   "source": [
    "sentences_f = []\n",
    "\n",
    "for idx in range(len(sentences)):\n",
    "    if sentences[idx] not in a:\n",
    "        sentences_f.append(sentences[idx])\n",
    "\n",
    "print(len(sentences_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('script_rmqa.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(sentences_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
